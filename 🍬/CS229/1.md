# Lecture 1

### 对机器学习的一个简单分类

>  他们之间的使用也许相互交叉，也可能互不干涉。但大体上它们是三种不一致的机器学习方法。

- 监督学习
- 无监督学习
- 强化学习

### 监督学习

#### 以房价的预测为例

- 给定一个数据集包含了 n 个样本，形式如下，并且可以获得一张散点图，以 $x$  为面积，以 $y$ 为价格。

$$
(x^{(1)},y^{(1)}),\dots(x^{(n)},y^{(n)})
$$

- 所以如何通过面积来预测价格？![image-20240619110617688](https://raw.githubusercontent.com/MarchPhantasia/pic/main/hexoblog/image-20240619110617688.png)

- 也许可以使用 **linear regression** 线性回归，或者做二次曲线的拟合。

- 更多的，可以用作预测的 Features 也可以存在更多，比如批量购买房子，那么同时**面积**，**数量**都会是影响价格的 feature，两个 feature 可以考虑画一个三维图。
- 如果现在是 2 Features/input ，1 label/output，那么数据集就是

$$
(x^{(1)},y^{(1)}),\dots(x^{(n)},y^{(n)}) \quad \quad 其中\  x^{(i)} = (x_1^{(1)},x_2^{(1)})
$$

- 通常认为 **supervisions（监督）** 也叫做 **labels/outputs（也就是上面所述的 y variable）**，称 **Dataset** 为训练的数据集，或者训练样本。![image-20240619112252207](/Users/phantasia/Library/Application Support/typora-user-images/image-20240619112252207.png)

- 当然仍然会存在更高维度的 Features，也会有更多的变量，such as
  - 楼层
  - 状态
  - 邮政编码等 最后通过映射得到了最终的 label y![image-20240619112635442](https://raw.githubusercontent.com/MarchPhantasia/pic/main/hexoblog/image-20240619112635442.png)

#### 两种类型的监督问题 Regression & Classification

- 通过区分 `label(y)` 的类型来进行对应的区分
- 如果你的 `label` 是实数，是一个连续变量，那么这就是一个 Regression 回归问题
- 如果你的 `label` 是一个离散变量，类似如果标签就是 yes or no （两个选择），那么这就是一个 classification 分类问题，这不是一个连续的预测问题。
- 用一个普通的房子和联排别墅为例，如果 size 和 lot size 可以映射到一个 classification，来代表最有可能对应的房屋类型。![image-20240619133526866](https://raw.githubusercontent.com/MarchPhantasia/pic/main/hexoblog/image-20240619133526866.png)

- 这两个不同类型有一条明显的线性区分，可以使用`Linear classifier`来区分他们，

#### Computer Vision 中的监督学习

- 比如 Image Classification 图像分类，在图像分类问题中，一般 Input 也就是 features 是 raw pixels of the image 也就是一些图像的原始像素，我们可以通过矩阵来表示这个数字序列。而 output/label 也就是识别出的主体。

- 也可以是Object localization and detection，对象的定位和检测。input 仍然是像素矩阵，而 output 则是一个 bounding box，用来划定主题的位置/范围。
- Machine translation 也是可能的，但是这个氛围要大的多，因为输入的 y 的中的每一个字都来源于集族，可以选择的范围是十分庞大的，这是一个离散的选择，你可以说虽然中文很庞大，但是中文的预料库总是有限的，但不同于一般的分类问题，只是 y 的集族巨大。

### 无监督学习

- 提供了一个 Dataset 但是没有 labels，如果仍然用上面房屋的例子来说，那就是我们知道输入的 features，但是我们并不知道根据这些 feature 可以得到什么样子的结果，也就是并不知道哪些房子会更可能售出。

#### 如果仍然使用房价为例子

- 无监督学习的本质就是希望在不了解输入与输出关系的情况下发现数据中的结构关系。![image-20240619164129503](https://raw.githubusercontent.com/MarchPhantasia/pic/main/hexoblog/image-20240619164129503.png)

- 在这种情况下，我们可以尝试将散点进行 cluster，当然 cluster 的选择是很多的，因为算法也不知道有联排别墅和独立房屋这两种东西，但是算法能够发现有明显的分类。<img src="https://raw.githubusercontent.com/MarchPhantasia/pic/main/hexoblog/image-20240619164325193.png" alt="image-20240619164325193" style="zoom:50%;" />

#### 其他类型的无监督学习例子

- Cluster Genes
- LSA（Latent Semantic Analysis）潜在语意分析
- Word Embeddings  如果你有一个非常大的未进行标注的数据集，需要做的就是通过算法在文档中进行学习，从而达到一个叫做 Word Embeddings 的目的，使用相应的向量来表示每个单词，因为向量都有点，就像离散世界中的数字表示。向量能够很好的表示单词的语义。单词之间的关系也会通过向量的关系进行编码。 
- Clustering Words with Similar Meanings（Hierarchically 按层次进行）
- Large Language Models   这是一个典型应用

### 增强学习

**主要思想**是学习做出顺序决策，和监督学习、无监督学习不同的是，前者做出的是决策，决策会产生长期后果，这个后果会影响到以后的决策（like alpha go），而后二者做出的是预测，

- 可以交互式地收集数据，通过 Training 得到的结果作为 Data Collection 的部分，通过 try Data Collection 得到的策略来收集反馈，再根据反馈改进策略。（那个机器人行走训练的视频）![image-20240620134125178](https://raw.githubusercontent.com/MarchPhantasia/pic/main/hexoblog/image-20240620134125178.png)